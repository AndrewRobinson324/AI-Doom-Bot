{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20572c5e",
   "metadata": {},
   "source": [
    "## VizDoom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8afc4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vizdoom in c:\\users\\rocky\\anaconda3\\lib\\site-packages (1.1.11)\n",
      "Requirement already satisfied: numpy in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from vizdoom) (1.20.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install vizdoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed23bce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMport vizdoom for the game env\n",
    "from vizdoom import *\n",
    "# Import random\n",
    "import random\n",
    "# import sleeping \n",
    "import time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2afffd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the game\n",
    "\n",
    "game = DoomGame()\n",
    "game.load_config('scenarios/basic.cfg')\n",
    "game.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d1ddab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe139cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.identity(3, dtype = np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba1b07f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# THese are all of the possible actions that you can take in the environment\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "695926c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0ce0b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "game.new_episode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1d22651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.is_episode_finished()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60d208be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.make_action(random.choice(actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47734e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  96.0\n",
      "Result: 71.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "Result: -375.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  96.0\n",
      "reward is :  -1.0\n",
      "Result: -75.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  96.0\n",
      "reward is :  -1.0\n",
      "Result: -210.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  97.0\n",
      "Result: 42.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "Result: -370.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  96.0\n",
      "reward is :  -1.0\n",
      "Result: 80.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  96.0\n",
      "reward is :  -1.0\n",
      "Result: 30.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "Result: -370.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -10.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "reward is :  -5.0\n",
      "Result: -365.0\n"
     ]
    }
   ],
   "source": [
    "# This is running the game using complete randomness just to test the model\n",
    "\n",
    "# Loops through 10 games\n",
    "episodes = 10\n",
    "for num_of_episode in range(episodes):\n",
    "    game.new_episode()\n",
    "    # While the game is not finished \n",
    "    while not game.is_episode_finished():\n",
    "        state = game.get_state()\n",
    "        # Allows us to get the image\n",
    "        img = state.screen_buffer\n",
    "        # This corresponds to our ammo\n",
    "        info = state.game_variables\n",
    "        # Takes an action\n",
    "        reward = game.make_action(random.choice(actions),5)\n",
    "        print(\"reward is : \",reward)\n",
    "        # Sleeps for a bit so that we are not moving too fast to see the actions\n",
    "        time.sleep(0.02)\n",
    "    print(\"Result:\" , game.get_total_reward())\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50d49fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f95e1a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to make it in Open AI Gym so lets set that up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bea16c",
   "metadata": {},
   "source": [
    "## Setting up Open AI Gym and Converting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85e1e8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\rocky\\anaconda3\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from gym) (1.20.3)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from gym) (1.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b880deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import environment base class from Open AI\n",
    "from gym import Env\n",
    "\n",
    "from gym.spaces import Discrete,Box\n",
    "\n",
    "# Lets us grescale our game so that it can compute faster\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0da375c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Discrete(3).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79c96a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0], dtype=uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[Discrete(3).sample()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c97be627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  3,  2,  6,  9,  0,  4,  7,  9,  1],\n",
       "       [ 4,  8,  6,  9, 10,  9,  9,  1,  3,  7],\n",
       "       [ 1,  0, 10,  4,  5,  9,  1,  6,  6,  8],\n",
       "       [ 8,  3,  4,  2,  1,  4,  9,  1,  7,  7],\n",
       "       [ 3,  7,  9, 10, 10,  6,  7,  5,  6,  0],\n",
       "       [ 7,  1,  8,  4,  9,  3,  0,  5,  5,  4],\n",
       "       [ 6, 10,  0,  9,  6,  0,  9,  9,  5,  1],\n",
       "       [ 9,  2,  0,  1,  6,  1,  1,  6,  5,  9],\n",
       "       [ 9,  5,  9,  5,  0,  4,  0,  1,  7,  7],\n",
       "       [ 2,  9,  4,  7, 10,  7,  9,  2,  8,  8]], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Box(low = 0, high = 10, shape = (10,10), dtype = np.uint8).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bfcbc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Vizdoom OpenAI Gym Environment\n",
    "class VizDoomGym(Env): \n",
    "    # Function that is called when we start the env\n",
    "    def __init__(self, render=False): \n",
    "        # Inherit from Env\n",
    "        super().__init__()\n",
    "        # Setup the game \n",
    "        self.game = DoomGame()\n",
    "        self.game.load_config('scenarios/basic.cfg')\n",
    "        \n",
    "        # Render frame logic\n",
    "        if render == False: \n",
    "            self.game.set_window_visible(False)\n",
    "        else:\n",
    "            self.game.set_window_visible(True)\n",
    "        \n",
    "        # Start the game \n",
    "        self.game.init()\n",
    "        \n",
    "        # Create the action space and observation space\n",
    "        self.observation_space = Box(low=0, high=255, shape=(100,160,1), dtype=np.uint8) \n",
    "        self.action_space = Discrete(3)\n",
    "        \n",
    "    # This is how we take a step in the environment\n",
    "    def step(self, action):\n",
    "        # Specify action and take step \n",
    "        actions = np.identity(3)\n",
    "        reward = self.game.make_action(actions[action], 4) \n",
    "        \n",
    "        # Get all the other stuff we need to retun \n",
    "        if self.game.get_state(): \n",
    "            state = self.game.get_state().screen_buffer\n",
    "            state = self.grayscale(state)\n",
    "            ammo = self.game.get_state().game_variables[0]\n",
    "            info = ammo\n",
    "        else: \n",
    "            state = np.zeros(self.observation_space.shape)\n",
    "            info = 0 \n",
    "        \n",
    "        info = {\"info\":info}\n",
    "        done = self.game.is_episode_finished()\n",
    "        \n",
    "        return state, reward, done, info \n",
    "    \n",
    "    # Define how to render the game or environment \n",
    "    def render(): \n",
    "        pass\n",
    "    \n",
    "    # What happens when we start a new game \n",
    "    def reset(self): \n",
    "        self.game.new_episode()\n",
    "        state = self.game.get_state().screen_buffer\n",
    "        return self.grayscale(state)\n",
    "    \n",
    "    # Grayscale the game frame and resize it \n",
    "    def grayscale(self, observation):\n",
    "        gray = cv2.cvtColor(np.moveaxis(observation, 0, -1), cv2.COLOR_BGR2GRAY)\n",
    "        resize = cv2.resize(gray, (160,100), interpolation=cv2.INTER_CUBIC)\n",
    "        state = np.reshape(resize, (100,160,1))\n",
    "        return state\n",
    "    \n",
    "    # Call to close down the game\n",
    "    def close(self): \n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4d220da",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = VizDoomGym(render = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d4bb52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "befcd113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[55],\n",
       "        [50],\n",
       "        [59],\n",
       "        ...,\n",
       "        [57],\n",
       "        [57],\n",
       "        [66]],\n",
       "\n",
       "       [[68],\n",
       "        [65],\n",
       "        [65],\n",
       "        ...,\n",
       "        [56],\n",
       "        [67],\n",
       "        [72]],\n",
       "\n",
       "       [[49],\n",
       "        [79],\n",
       "        [66],\n",
       "        ...,\n",
       "        [79],\n",
       "        [51],\n",
       "        [29]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[75],\n",
       "        [63],\n",
       "        [62],\n",
       "        ...,\n",
       "        [44],\n",
       "        [71],\n",
       "        [60]],\n",
       "\n",
       "       [[15],\n",
       "        [48],\n",
       "        [47],\n",
       "        ...,\n",
       "        [49],\n",
       "        [69],\n",
       "        [47]],\n",
       "\n",
       "       [[22],\n",
       "        [14],\n",
       "        [26],\n",
       "        ...,\n",
       "        [57],\n",
       "        [37],\n",
       "        [39]]], dtype=uint8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1dd00919",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa210e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common import env_checker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9579ffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31967305",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#from matplotlib import pyplot as plt\n",
    "#plt.imshow(cv2.cvtColor(state,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8df6ce6",
   "metadata": {},
   "source": [
    "#  Setting up the Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec1b689a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/cu113/torch_stable.html\n",
      "Requirement already satisfied: torch==1.10.1+cu113 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (1.10.1+cu113)\n",
      "Requirement already satisfied: torchvision==0.11.2+cu113 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (0.11.2+cu113)\n",
      "Requirement already satisfied: torchaudio===0.10.1+cu113 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (0.10.1+cu113)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from torch==1.10.1+cu113) (3.10.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from torchvision==0.11.2+cu113) (8.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from torchvision==0.11.2+cu113) (1.20.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio===0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9bdb55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in c:\\users\\rocky\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: torch>=1.8.1 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.10.1+cu113)\n",
      "Requirement already satisfied: pandas in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.3.4)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.6.0)\n",
      "Requirement already satisfied: gym<0.20,>=0.17 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.19.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (3.4.3)\n",
      "Requirement already satisfied: atari-py~=0.2.0 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.2.9)\n",
      "Requirement already satisfied: psutil in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (5.8.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (4.5.5.62)\n",
      "Requirement already satisfied: pillow in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (8.4.0)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.7.0)\n",
      "Requirement already satisfied: six in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from atari-py~=0.2.0->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (2.0.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (2.3.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (58.0.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (3.19.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.8.1)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.37.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.43.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (3.3.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->stable-baselines3[extra]) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->stable-baselines3[extra]) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable-baselines3[extra]) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable-baselines3[extra]) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable-baselines3[extra]) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable-baselines3[extra]) (2.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from torch>=1.8.1->stable-baselines3[extra]) (3.10.0.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\rocky\\anaconda3\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2021.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3[extra]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fd557bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb06bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "042ea5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/train_basic'\n",
    "LOG_DIR = './logs/log_basic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2af496d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d9d73e",
   "metadata": {},
   "source": [
    "# Let's Train this Model now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ecba0ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90e15bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an environment\n",
    "\n",
    "env = VizDoomGym()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d19d340b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rocky\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:80: UserWarning: CUDA initialization: CUDA driver initialization failed, you might not have a CUDA gpu. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "C:\\Users\\rocky\\anaconda3\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:137: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 260`, after every 4 untruncated mini-batches, there will be a truncated mini-batch of size 4\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=260 and n_envs=1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "# creates the model, Cnn because we are passing in images so we need a convolutional neural network\n",
    "model = PPO(\"CnnPolicy\", env, tensorboard_log = LOG_DIR, verbose = 1, learning_rate = 0.0001, n_steps = 260 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb50da8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/log_basic\\PPO_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.1     |\n",
      "|    ep_rew_mean     | -10.2    |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 260      |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 23.9         |\n",
      "|    ep_rew_mean          | -29.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 13           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 520          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038518147 |\n",
      "|    clip_fraction        | 0.0228       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 2.36e-05     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.2e+03      |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | 0.00507      |\n",
      "|    value_loss           | 3.49e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 25.3         |\n",
      "|    ep_rew_mean          | -39.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 14           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 780          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013174384 |\n",
      "|    clip_fraction        | 0.298        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.0145       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 468          |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | 0.00983      |\n",
      "|    value_loss           | 2.92e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 23.2        |\n",
      "|    ep_rew_mean          | -29.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 1040        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013544542 |\n",
      "|    clip_fraction        | 0.396       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.0148      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.32e+03    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | 0.00101     |\n",
      "|    value_loss           | 3.52e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 22.8         |\n",
      "|    ep_rew_mean          | -26.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 14           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 88           |\n",
      "|    total_timesteps      | 1300         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070718825 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.0642       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.67e+03     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | 0.00145      |\n",
      "|    value_loss           | 5.59e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 23.3        |\n",
      "|    ep_rew_mean          | -27.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 1560        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013393757 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.0343      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.95e+03    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 4.69e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 23.4        |\n",
      "|    ep_rew_mean          | -29.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 1820        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009624225 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.0663      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 366         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00974    |\n",
      "|    value_loss           | 5.39e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 24.2         |\n",
      "|    ep_rew_mean          | -35.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 15           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 137          |\n",
      "|    total_timesteps      | 2080         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035489216 |\n",
      "|    clip_fraction        | 0.000625     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.179        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.26e+03     |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | 0.000615     |\n",
      "|    value_loss           | 3.32e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 24.9        |\n",
      "|    ep_rew_mean          | -40.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 2340        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007416241 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.0967      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.42e+03    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00678    |\n",
      "|    value_loss           | 3.71e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 24.3        |\n",
      "|    ep_rew_mean          | -36.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 2600        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012689012 |\n",
      "|    clip_fraction        | 0.353       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.163       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 245         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | 0.00766     |\n",
      "|    value_loss           | 4.36e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 25.4        |\n",
      "|    ep_rew_mean          | -44.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 187         |\n",
      "|    total_timesteps      | 2860        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010064041 |\n",
      "|    clip_fraction        | 0.0859      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.954      |\n",
      "|    explained_variance   | 0.2         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 852         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | 0.000514    |\n",
      "|    value_loss           | 5.63e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 25          |\n",
      "|    ep_rew_mean          | -41.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 204         |\n",
      "|    total_timesteps      | 3120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038709305 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.12e+03    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | 0.00344     |\n",
      "|    value_loss           | 6.77e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 26.5         |\n",
      "|    ep_rew_mean          | -50.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 15           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 220          |\n",
      "|    total_timesteps      | 3380         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052669537 |\n",
      "|    clip_fraction        | 0.165        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.988       |\n",
      "|    explained_variance   | 0.31         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.69e+03     |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | 0.00239      |\n",
      "|    value_loss           | 4.87e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.9        |\n",
      "|    ep_rew_mean          | -57.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 237         |\n",
      "|    total_timesteps      | 3640        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024821142 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.952      |\n",
      "|    explained_variance   | -0.214      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.76e+03    |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | 0.00829     |\n",
      "|    value_loss           | 5.97e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.7        |\n",
      "|    ep_rew_mean          | -61.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 255         |\n",
      "|    total_timesteps      | 3900        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008012356 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.986      |\n",
      "|    explained_variance   | 0.0504      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 721         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | 0.0141      |\n",
      "|    value_loss           | 4.3e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.6        |\n",
      "|    ep_rew_mean          | -60.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 273         |\n",
      "|    total_timesteps      | 4160        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007605908 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.0132      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.7e+03     |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00883    |\n",
      "|    value_loss           | 7.88e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.7        |\n",
      "|    ep_rew_mean          | -62.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 292         |\n",
      "|    total_timesteps      | 4420        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005152899 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -0.0021     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.54e+03    |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 6.45e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.4        |\n",
      "|    ep_rew_mean          | -53.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 309         |\n",
      "|    total_timesteps      | 4680        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015648577 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 888         |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 4.33e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 26.9         |\n",
      "|    ep_rew_mean          | -48.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 14           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 330          |\n",
      "|    total_timesteps      | 4940         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0153226005 |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0.324        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 3.03e+03     |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0071      |\n",
      "|    value_loss           | 5.04e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.3        |\n",
      "|    ep_rew_mean          | -49.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 348         |\n",
      "|    total_timesteps      | 5200        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060545515 |\n",
      "|    clip_fraction        | 0.478       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.208       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.21e+03    |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | 0.0189      |\n",
      "|    value_loss           | 3.6e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 27         |\n",
      "|    ep_rew_mean          | -47.8      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 14         |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 366        |\n",
      "|    total_timesteps      | 5460       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03236779 |\n",
      "|    clip_fraction        | 0.693      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.847     |\n",
      "|    explained_variance   | 0.175      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 5.51e+03   |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | 0.0437     |\n",
      "|    value_loss           | 3.26e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 26          |\n",
      "|    ep_rew_mean          | -40.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 385         |\n",
      "|    total_timesteps      | 5720        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022067737 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.971      |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00014    |\n",
      "|    value_loss           | 2.63e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 20.9       |\n",
      "|    ep_rew_mean          | -11.6      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 14         |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 404        |\n",
      "|    total_timesteps      | 5980       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04334297 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.921     |\n",
      "|    explained_variance   | 0.406      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 2.08e+03   |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | 0.0284     |\n",
      "|    value_loss           | 3.56e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 22          |\n",
      "|    ep_rew_mean          | -18         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 422         |\n",
      "|    total_timesteps      | 6240        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018811816 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.826      |\n",
      "|    explained_variance   | 0.59        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.61e+03    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 0.0191      |\n",
      "|    value_loss           | 3e+03       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 21.6      |\n",
      "|    ep_rew_mean          | -15.7     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 14        |\n",
      "|    iterations           | 25        |\n",
      "|    time_elapsed         | 441       |\n",
      "|    total_timesteps      | 6500      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3638773 |\n",
      "|    clip_fraction        | 0.692     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.434    |\n",
      "|    explained_variance   | 0.295     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 344       |\n",
      "|    n_updates            | 240       |\n",
      "|    policy_gradient_loss | 0.0787    |\n",
      "|    value_loss           | 2.7e+03   |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 22.7        |\n",
      "|    ep_rew_mean          | -21.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 459         |\n",
      "|    total_timesteps      | 6760        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001756521 |\n",
      "|    clip_fraction        | 0.0553      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.218      |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 785         |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | 0.00517     |\n",
      "|    value_loss           | 3.26e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.9        |\n",
      "|    ep_rew_mean          | -11.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 477         |\n",
      "|    total_timesteps      | 7020        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016475478 |\n",
      "|    clip_fraction        | 0.0462      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.256      |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 589         |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.000704   |\n",
      "|    value_loss           | 2.36e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 20.5       |\n",
      "|    ep_rew_mean          | -9.56      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 14         |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 495        |\n",
      "|    total_timesteps      | 7280       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03187211 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.315     |\n",
      "|    explained_variance   | 0.624      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 229        |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | 0.0132     |\n",
      "|    value_loss           | 2.26e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.9        |\n",
      "|    ep_rew_mean          | -12.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 514         |\n",
      "|    total_timesteps      | 7540        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042813376 |\n",
      "|    clip_fraction        | 0.0641      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.214      |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 69          |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | 0.0257      |\n",
      "|    value_loss           | 2.59e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 21.4        |\n",
      "|    ep_rew_mean          | -15.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 532         |\n",
      "|    total_timesteps      | 7800        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030688569 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.3        |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 553         |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | 0.000298    |\n",
      "|    value_loss           | 3.58e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 21.2        |\n",
      "|    ep_rew_mean          | -13.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 551         |\n",
      "|    total_timesteps      | 8060        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020088896 |\n",
      "|    clip_fraction        | 0.0481      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.152      |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 958         |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | 0.00556     |\n",
      "|    value_loss           | 2.75e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 21.6        |\n",
      "|    ep_rew_mean          | -15.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 570         |\n",
      "|    total_timesteps      | 8320        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024093281 |\n",
      "|    clip_fraction        | 0.0434      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.143      |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.05e+03    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | 0.00165     |\n",
      "|    value_loss           | 2.61e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 22.1        |\n",
      "|    ep_rew_mean          | -18.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 590         |\n",
      "|    total_timesteps      | 8580        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.074447334 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 463         |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | 0.0789      |\n",
      "|    value_loss           | 4.5e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 23.4       |\n",
      "|    ep_rew_mean          | -25        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 14         |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 608        |\n",
      "|    total_timesteps      | 8840       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01563878 |\n",
      "|    clip_fraction        | 0.0178     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0827    |\n",
      "|    explained_variance   | -0.0522    |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.05e+03   |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | 0.0194     |\n",
      "|    value_loss           | 4.26e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 22.3       |\n",
      "|    ep_rew_mean          | -17.8      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 14         |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 627        |\n",
      "|    total_timesteps      | 9100       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03056243 |\n",
      "|    clip_fraction        | 0.0813     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.207     |\n",
      "|    explained_variance   | 0.159      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 146        |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | 0.00533    |\n",
      "|    value_loss           | 4.22e+03   |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 23.5          |\n",
      "|    ep_rew_mean          | -24.2         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 14            |\n",
      "|    iterations           | 36            |\n",
      "|    time_elapsed         | 647           |\n",
      "|    total_timesteps      | 9360          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040071606 |\n",
      "|    clip_fraction        | 0.00594       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0402       |\n",
      "|    explained_variance   | 0.56          |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 621           |\n",
      "|    n_updates            | 350           |\n",
      "|    policy_gradient_loss | 0.00146       |\n",
      "|    value_loss           | 2.45e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 24.1         |\n",
      "|    ep_rew_mean          | -26.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 14           |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 666          |\n",
      "|    total_timesteps      | 9620         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077708648 |\n",
      "|    clip_fraction        | 0.0331       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.049       |\n",
      "|    explained_variance   | 0.508        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 3.55e+03     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00209     |\n",
      "|    value_loss           | 3.69e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 22         |\n",
      "|    ep_rew_mean          | -13.3      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 14         |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 686        |\n",
      "|    total_timesteps      | 9880       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00828504 |\n",
      "|    clip_fraction        | 0.0475     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.145     |\n",
      "|    explained_variance   | 0.545      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 2.71e+03   |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.00345   |\n",
      "|    value_loss           | 2.98e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 22.8         |\n",
      "|    ep_rew_mean          | -17.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 14           |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 704          |\n",
      "|    total_timesteps      | 10140        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061177155 |\n",
      "|    clip_fraction        | 0.0334       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.113       |\n",
      "|    explained_variance   | 0.777        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 793          |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | 0.00435      |\n",
      "|    value_loss           | 1.96e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 22.1        |\n",
      "|    ep_rew_mean          | -14.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 722         |\n",
      "|    total_timesteps      | 10400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023459641 |\n",
      "|    clip_fraction        | 0.0391      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0753     |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.78e+03    |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | 0.0112      |\n",
      "|    value_loss           | 1.68e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 21.4       |\n",
      "|    ep_rew_mean          | -10.9      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 14         |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 740        |\n",
      "|    total_timesteps      | 10660      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04001603 |\n",
      "|    clip_fraction        | 0.0778     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.202     |\n",
      "|    explained_variance   | 0.597      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 401        |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | 0.0428     |\n",
      "|    value_loss           | 2.07e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.3        |\n",
      "|    ep_rew_mean          | -8.09       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 757         |\n",
      "|    total_timesteps      | 10920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051513948 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.355      |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 146         |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | 0.0066      |\n",
      "|    value_loss           | 1.67e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 19.9       |\n",
      "|    ep_rew_mean          | -6.23      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 14         |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 776        |\n",
      "|    total_timesteps      | 11180      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13780627 |\n",
      "|    clip_fraction        | 0.375      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.387     |\n",
      "|    explained_variance   | 0.433      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 449        |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.00923   |\n",
      "|    value_loss           | 1.93e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17236/1785440237.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    297\u001b[0m     ) -> \"PPO\":\n\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m         return super(PPO, self).learn(\n\u001b[0m\u001b[0;32m    300\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m                 \u001b[1;31m# Clip grad norm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m                 \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    131\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             F.adam(params_with_grad,\n\u001b[0m\u001b[0;32m    134\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps = 100000,callback = callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ca2af76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ep_len_mean = how many frames it is on average\n",
    "# ep_rew_mean = sum of average reward\n",
    "# approx_kl = measures the difference between our current and previous training\n",
    "# policy_gradient_loss = how well our agent can capatilize on an advantage\n",
    "# value_loss = how well its able to predict the value of each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3be7dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This does not seem to be training well in fact the reward is not going up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ab6748f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\"CnnPolicy\", env, tensorboard_log = LOG_DIR, verbose = 1, learning_rate = 0.0001, n_steps = 2048 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42ecc19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/log_basic\\PPO_2\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.8     |\n",
      "|    ep_rew_mean     | -75      |\n",
      "| time/              |          |\n",
      "|    fps             | 32       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 62       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.5       |\n",
      "|    ep_rew_mean          | -77.1      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 21         |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 189        |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00792253 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.09      |\n",
      "|    explained_variance   | -0.000161  |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.14e+03   |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.000433  |\n",
      "|    value_loss           | 2.48e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.1        |\n",
      "|    ep_rew_mean          | -63         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 324         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009674029 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.0819      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.04e+03    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0011     |\n",
      "|    value_loss           | 2.73e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 26.1        |\n",
      "|    ep_rew_mean          | -46.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 469         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012204825 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.42e+03    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | 0.00303     |\n",
      "|    value_loss           | 2.76e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 24.7        |\n",
      "|    ep_rew_mean          | -34.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 620         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014054032 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.77e+03    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0035     |\n",
      "|    value_loss           | 3.76e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 24.3        |\n",
      "|    ep_rew_mean          | -33.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 775         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015132143 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.07e+03    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | 0.00119     |\n",
      "|    value_loss           | 4.2e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 18.8       |\n",
      "|    ep_rew_mean          | 1.04       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 15         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 929        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01841212 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.03      |\n",
      "|    explained_variance   | 0.507      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.49e+03   |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.00205   |\n",
      "|    value_loss           | 3.79e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 14.1        |\n",
      "|    ep_rew_mean          | 31.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 1061        |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018741224 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.992      |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.59e+03    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | 0.00411     |\n",
      "|    value_loss           | 3.89e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.9        |\n",
      "|    ep_rew_mean          | 3.61        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 1162        |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030297378 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.927      |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.14e+03    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | 0.0212      |\n",
      "|    value_loss           | 3.54e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.2        |\n",
      "|    ep_rew_mean          | 34.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 1264        |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017389432 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.93       |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.4e+03     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.000756   |\n",
      "|    value_loss           | 2.83e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 12.6     |\n",
      "|    ep_rew_mean          | 35       |\n",
      "| time/                   |          |\n",
      "|    fps                  | 16       |\n",
      "|    iterations           | 11       |\n",
      "|    time_elapsed         | 1364     |\n",
      "|    total_timesteps      | 22528    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.038487 |\n",
      "|    clip_fraction        | 0.272    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.9     |\n",
      "|    explained_variance   | 0.608    |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 1.27e+03 |\n",
      "|    n_updates            | 100      |\n",
      "|    policy_gradient_loss | 0.00767  |\n",
      "|    value_loss           | 2.47e+03 |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.85        |\n",
      "|    ep_rew_mean          | 52.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 1544        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016300198 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.843      |\n",
      "|    explained_variance   | 0.755       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.01e+03    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | 0.00948     |\n",
      "|    value_loss           | 2.1e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.65        |\n",
      "|    ep_rew_mean          | 52.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 1712        |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015611155 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.779      |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 881         |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | 0.0118      |\n",
      "|    value_loss           | 2.01e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.6         |\n",
      "|    ep_rew_mean          | 53.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 1881        |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024923775 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.779      |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.35e+03    |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | 0.0136      |\n",
      "|    value_loss           | 1.59e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 7.57      |\n",
      "|    ep_rew_mean          | 65.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 15        |\n",
      "|    iterations           | 15        |\n",
      "|    time_elapsed         | 1967      |\n",
      "|    total_timesteps      | 30720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0904177 |\n",
      "|    clip_fraction        | 0.292     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.773    |\n",
      "|    explained_variance   | 0.819     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 571       |\n",
      "|    n_updates            | 140       |\n",
      "|    policy_gradient_loss | 0.00279   |\n",
      "|    value_loss           | 1.31e+03  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.97        |\n",
      "|    ep_rew_mean          | 70.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 2072        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022268638 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.739      |\n",
      "|    explained_variance   | 0.673       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 371         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | 0.00802     |\n",
      "|    value_loss           | 897         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 7.38       |\n",
      "|    ep_rew_mean          | 67.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 2170       |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05714419 |\n",
      "|    clip_fraction        | 0.384      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.694     |\n",
      "|    explained_variance   | 0.457      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 346        |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.00175   |\n",
      "|    value_loss           | 716        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 6.17       |\n",
      "|    ep_rew_mean          | 74.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 2269       |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04808226 |\n",
      "|    clip_fraction        | 0.288      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.706     |\n",
      "|    explained_variance   | 0.695      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 327        |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.00586   |\n",
      "|    value_loss           | 681        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.99        |\n",
      "|    ep_rew_mean          | 68.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 2374        |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030419605 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.652      |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 347         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00863    |\n",
      "|    value_loss           | 608         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.42       |\n",
      "|    ep_rew_mean          | 78.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 2481       |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06692131 |\n",
      "|    clip_fraction        | 0.342      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.597     |\n",
      "|    explained_variance   | 0.689      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 123        |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | 0.0304     |\n",
      "|    value_loss           | 360        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.56        |\n",
      "|    ep_rew_mean          | 77.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 2591        |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036889315 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.548      |\n",
      "|    explained_variance   | 0.839       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 382         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | 0.00385     |\n",
      "|    value_loss           | 513         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.69        |\n",
      "|    ep_rew_mean          | 82.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 2699        |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059906527 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.442      |\n",
      "|    explained_variance   | 0.815       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 97.2        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | 0.00778     |\n",
      "|    value_loss           | 333         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.67        |\n",
      "|    ep_rew_mean          | 83          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 2807        |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044011716 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.405      |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 98.6        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | 0.0115      |\n",
      "|    value_loss           | 190         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.41       |\n",
      "|    ep_rew_mean          | 84.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 2917       |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04874167 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.399     |\n",
      "|    explained_variance   | 0.516      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 113        |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | 0.0309     |\n",
      "|    value_loss           | 154        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.3         |\n",
      "|    ep_rew_mean          | 84.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 3033        |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024983557 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.324      |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 33.4        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | 0.0246      |\n",
      "|    value_loss           | 46.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.49        |\n",
      "|    ep_rew_mean          | 83.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 3145        |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014961315 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.244      |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 84.6        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | 0.0246      |\n",
      "|    value_loss           | 83.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17236/1785440237.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    297\u001b[0m     ) -> \"PPO\":\n\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m         return super(PPO, self).learn(\n\u001b[0m\u001b[0;32m    300\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m             \u001b[0mcontinue_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcontinue_training\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    167\u001b[0m                 \u001b[1;31m# Convert to pytorch tensor or to TensorDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m                 \u001b[0mobs_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobs_as_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_last_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m                 \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m             \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\policies.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, obs, deterministic)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \"\"\"\n\u001b[0;32m    585\u001b[0m         \u001b[1;31m# Preprocess the observation if needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m         \u001b[0mlatent_pi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_vf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmlp_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Evaluate the values for the given observations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\policies.py\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures_extractor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"No features extractor was set\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mpreprocessed_obs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_obs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize_images\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessed_obs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_constructor_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\torch_layers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, observations)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobservations\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1297\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1299\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1300\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps = 100000,callback = callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eaf11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on a new model with better n_steps so hopefully it will learn better than the previous model\n",
    "# Seems to have worked much better with a higher n_steps\n",
    "# This is taking too long to keep running and the reward is already quite good after only half of the timesteps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d5d882",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e2d0d394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload are best mode \n",
    "model = PPO.load('./train/train_basic/best_model_60000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c872a200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e94c2d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = VizDoomGym(render = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da494e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, _= evaluate_policy(model,env,n_eval_episodes = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d50563ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.61"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b225ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "52dc0234",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load('./train/train_basic/best_model_10000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a628530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, _= evaluate_policy(model,env,n_eval_episodes = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "631c6353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-87.38"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057062c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
